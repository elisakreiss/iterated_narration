---
title: "09_subj-ratings_analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(cowplot)
library(tidyverse)
library(summarytools)
library(gridExtra)
library(corrplot)
library(here)

theme_set(theme_bw(18))
theme_set(theme_cowplot(font_size=12))
```

```{r import data, include=FALSE}
df = read_csv(here("data","01_pilot","09_subjective-ratings","raw.csv"))

glimpse(df)
```

Overall: 72 participants

## Additional Info

```{r info, echo=FALSE, fig.height=11, fig.width=9, message=FALSE, warning=FALSE}

# other info
df_subj = df %>% 
  select(id,age,gender,education,languages,enjoyment,timeSpent,HitCorrect) %>% 
  distinct() %>% 
  mutate_at(vars(languages), funs(str_to_lower(.))) %>% 
  mutate_at(vars(age), funs(as.integer(.))) %>% 
  mutate_at(vars(HitCorrect),
            funs(ifelse(HitCorrect==0,"no",ifelse(HitCorrect==404,"confused","yes")))) %>% 
  mutate_at(vars(education), funs(str_replace_all(.,"graduated_", "")))

p_age = ggplot(df_subj,aes(x=age)) + 
  geom_bar(width = .5,
           fill = "orange") 

p_gen = ggplot(df_subj,aes(x=gender)) +
  geom_bar(width = .5,
           fill = "orange")

p_edu = ggplot(df_subj,aes(x=education)) +
  geom_bar(width = .5,
           fill = "orange") +
  theme(axis.text.x = element_text(angle = 25, hjust = 1))

p_lang = ggplot(df_subj,aes(x=languages)) +
  geom_bar(width = .5,
           fill = "orange")

p_enj = ggplot(df_subj,aes(x=enjoyment)) + 
  geom_bar(width = .5,
           fill = "orange")

p_time = ggplot(df_subj,aes(x=timeSpent)) +
  geom_histogram(fill = "orange")

p_HitCorrect = ggplot(df_subj,aes(x=HitCorrect)) + 
  geom_bar(width = .5,
           fill = "orange") 

plot_grid(p_age,p_gen,p_edu,p_lang,p_enj,p_time,p_HitCorrect, labels = "AUTO", ncol = 2, align = 'v')
# grid.arrange(p_age,p_gen,p_edu,p_lang,p_enj,p_time,p_HitCorrect)
```

This looks good, I think.

## Correlation between questions

I excluded all participants who rated more than 2 of the control questions wrong (i.e., participants who answered them correctly or clicked "Doesn't apply" are kept.)<br>
For the computation of the correlation, I used Pearson.<br>
I have thought about applying PCA (as Judith and I had discussed), but I don't see how this helps me selecting the questions. From my understanding, PCA creates orthogonal eigenvectors which are linear combinations of the original variables to achieve a more accurate representation of the data. One can then compute the correlation with the original variables, but I don't see why this would help us any more than just looking at the correlations and choose one out of the two that highly correlate. Do I miss something here?

```{r correlation, echo=FALSE, fig.height=9, fig.width=9}
df_clean = df %>%
  select(id,generation,chain,trial_type,question,slider_val,box_checked,story_reproduction,story_title,trial_number)

df_corr = df_clean %>% 
  mutate(response=ifelse(box_checked=="false",slider_val,NA)) %>% 
  select(id,trial_type,slider_val) %>% 
  group_by(id) %>% 
  spread(trial_type,slider_val) %>% 
  ungroup() %>% 
  mutate(pay_attention=ifelse(((control1_false>50) + (control2_false>50) + (control3_true<50) + (control4_true>50)) > 2,FALSE,TRUE)) %>% 
  filter(pay_attention==TRUE) %>%  
  select(-id,-control1_false,-control2_false,-control3_true,-control4_true, -pay_attention)

# chart.Correlation(df_corr, histogram=TRUE, pch=19)
res = cor(df_corr, method="pearson", use="complete.obs")
corrplot(res, method = "number", type = "upper", order = "FPC", 
         tl.col = "black", tl.srt = 45)
```

Strongest correlations:<br>

- info_reliability (*"How reliable do you consider the presented information to be?"*) and author_trust (*"How much do you trust the author?"*): 0.66
- story_emotion (*"How emotionally is the story told?"*) and author_judgmental (*"How judgmental is the author?"*): 0.59
- suspect_convictionJustified (*"How justified would a conviction of the suspect(s), i.e., the person/people underlined in the story, be?"*) and suspect_committedCrime (*"How likely is it that the suspect is / the suspects are guilty? (i.e., the person/people underlined in the story)"*): 0.59
- reader_emotion (*"How affected do you feel by the story?"*) and story_emotion (*"How emotionally is the story told?"*): 0.54
- story_subjectivity (*"How objectively / subjectively written is the story?"*) and author_judgmental (*"How judgmental is the author?"*): 0.51

Story_emotion and author_judgmental each correlate with eacher other and one more question (story_emotion: reader_emotion; author_judgmental: story_subjectivity.)




